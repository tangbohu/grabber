#!/usr/bin/python
# -*- coding: utf-8 -*- 
"""dong fang cai fu wang"""
import  fetchWeb 
from web import Web
from BeautifulSoup import BeautifulSoup

import urllib2
import sys
import chardet
import time
import datetime
from info import Info




class dfcfw(Web):
    def __init__(self,dic):
         Web.__init__(self,dic)
         self.url='http://stock.eastmoney.com/news/cgszb.html'
         self.soup=None
         self.fromweb="东方财富网"
         print 'dfcfw init ok'
             
    def readWeb(self,url):
       html=urllib2.urlopen(url).read()
       localcode= sys.getfilesystemencoding()      # local encode format  
       try:
           return BeautifulSoup(html.decode('gb2312','ignore').encode(localcode))
       except:
           return BeautifulSoup("")

     
    def getChildSoup(self,link):
      #  print '--------------------------------------------------------','\n'
        childSoup=self.readWeb(link)
        #print childSoup
       # print '--------------------------------------------------------','\n'
        return childSoup  
  
    def searchTag(self,strinfo):

          result=[]
          for key in self.searchdict:
             print 'searching ',key
             if(strinfo.find(key)!=-1):
                print 'find ',key
	        result.append(key)
	     else:
                 pass
         # print result
	  return  result



    def linkAnalysis(self,link):
        temp=link.find("a")
        address=temp["href"]   
        brief=temp["title"]   
        timenow=link.find("span").string
        timenow+=":59"
        now= time.strptime(timenow, '%Y-%m-%d %H:%M:%S')
        print 'news time:',timenow
        print 'update time :',self.updateTime
        if time.mktime(now)<time.mktime(self.updateTime):
            print 'has no latest news'
            return 0
        else :
            print 'find latest news'
        print 'link address is : ',address 
        print 'link content is :', brief 
        childSoup=self.getChildSoup(address)      
        newsContent=childSoup.find(attrs={"class":"Body","id":"ContentBody"})

        stringTemp=""
        if newsContent==None:
            return 1
        for content in newsContent:
            stringTemp+=str(content)
#        print stringTemp
#        print searchdict
        tags=self.searchTag(stringTemp)
       # print 'tags is ',tags
        if tags:
               newin=Info()
               newin.addLink(address,brief)
               for tag  in tags:
                  newin.addTag(tag)
                  print newin
                  print 'in this news find ',tag
               self.addInfo(newin)
               print 'useful info'
        else:
               print 'useless info'
        print '------------------------- one link analysis end ','------------------'
        return 1
        

    def collectInfo(self):
        self.clearInfo()
        self.soup=self.readWeb(self.url)
        #print self.soup
        temptime=time.localtime()
        print 'starting learning from ',self.url
        print 'starting 东方财富网啊'
        linkVector=self.soup.find(name="div",attrs={"class":"list"}).findAll(name="li")
      #  print linkVector
        for link in linkVector:
            if not self.linkAnalysis(link):
                 break
        #self.linkAnalysis(linkVector[0])          

        self.updateTime=temptime
        print 'update done'
    

        

if __name__=='__main__':
    search=['光大证券']
    a=dfcfw()
    a.collectInfo(search)
    
    
